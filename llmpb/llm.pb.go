// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.10
// 	protoc        v6.33.0
// source: llm.proto

package llmpb

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

// ChatRequest is sent from client to server during a streaming session.
type ChatRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Request:
	//
	//	*ChatRequest_Start
	//	*ChatRequest_Message
	//	*ChatRequest_Abort
	//	*ChatRequest_ToolResult
	Request       isChatRequest_Request `protobuf_oneof:"request"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatRequest) Reset() {
	*x = ChatRequest{}
	mi := &file_llm_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatRequest) ProtoMessage() {}

func (x *ChatRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatRequest.ProtoReflect.Descriptor instead.
func (*ChatRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{0}
}

func (x *ChatRequest) GetRequest() isChatRequest_Request {
	if x != nil {
		return x.Request
	}
	return nil
}

func (x *ChatRequest) GetStart() *StartChatRequest {
	if x != nil {
		if x, ok := x.Request.(*ChatRequest_Start); ok {
			return x.Start
		}
	}
	return nil
}

func (x *ChatRequest) GetMessage() *UserMessage {
	if x != nil {
		if x, ok := x.Request.(*ChatRequest_Message); ok {
			return x.Message
		}
	}
	return nil
}

func (x *ChatRequest) GetAbort() *AbortRequest {
	if x != nil {
		if x, ok := x.Request.(*ChatRequest_Abort); ok {
			return x.Abort
		}
	}
	return nil
}

func (x *ChatRequest) GetToolResult() *ToolResult {
	if x != nil {
		if x, ok := x.Request.(*ChatRequest_ToolResult); ok {
			return x.ToolResult
		}
	}
	return nil
}

type isChatRequest_Request interface {
	isChatRequest_Request()
}

type ChatRequest_Start struct {
	// Initial request to start a chat
	Start *StartChatRequest `protobuf:"bytes,1,opt,name=start,proto3,oneof"`
}

type ChatRequest_Message struct {
	// Send a user message during the conversation
	Message *UserMessage `protobuf:"bytes,2,opt,name=message,proto3,oneof"`
}

type ChatRequest_Abort struct {
	// Abort the current generation
	Abort *AbortRequest `protobuf:"bytes,3,opt,name=abort,proto3,oneof"`
}

type ChatRequest_ToolResult struct {
	// Provide tool results (for function calling)
	ToolResult *ToolResult `protobuf:"bytes,4,opt,name=tool_result,json=toolResult,proto3,oneof"`
}

func (*ChatRequest_Start) isChatRequest_Request() {}

func (*ChatRequest_Message) isChatRequest_Request() {}

func (*ChatRequest_Abort) isChatRequest_Request() {}

func (*ChatRequest_ToolResult) isChatRequest_Request() {}

// StartChatRequest initializes a chat session.
type StartChatRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// API key for authentication (X-API-Key)
	ApiKey string `protobuf:"bytes,1,opt,name=api_key,json=apiKey,proto3" json:"api_key,omitempty"`
	// System prompt for the conversation
	SystemPrompt string `protobuf:"bytes,2,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"`
	// Model tier: "haiku", "sonnet", "opus"
	Model string `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	// Maximum tokens to generate
	MaxTokens int32 `protobuf:"varint,4,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	// Temperature (0.0-1.0)
	Temperature float32 `protobuf:"fixed32,5,opt,name=temperature,proto3" json:"temperature,omitempty"`
	// Initial messages for context (optional)
	Messages []*Message `protobuf:"bytes,6,rep,name=messages,proto3" json:"messages,omitempty"`
	// Tools available for function calling (optional)
	Tools []*ToolDefinition `protobuf:"bytes,7,rep,name=tools,proto3" json:"tools,omitempty"`
	// Unique request ID for tracking
	RequestId     string `protobuf:"bytes,8,opt,name=request_id,json=requestId,proto3" json:"request_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *StartChatRequest) Reset() {
	*x = StartChatRequest{}
	mi := &file_llm_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *StartChatRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*StartChatRequest) ProtoMessage() {}

func (x *StartChatRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use StartChatRequest.ProtoReflect.Descriptor instead.
func (*StartChatRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{1}
}

func (x *StartChatRequest) GetApiKey() string {
	if x != nil {
		return x.ApiKey
	}
	return ""
}

func (x *StartChatRequest) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *StartChatRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *StartChatRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *StartChatRequest) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *StartChatRequest) GetMessages() []*Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *StartChatRequest) GetTools() []*ToolDefinition {
	if x != nil {
		return x.Tools
	}
	return nil
}

func (x *StartChatRequest) GetRequestId() string {
	if x != nil {
		return x.RequestId
	}
	return ""
}

// UserMessage sends a message from the user.
type UserMessage struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *UserMessage) Reset() {
	*x = UserMessage{}
	mi := &file_llm_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *UserMessage) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*UserMessage) ProtoMessage() {}

func (x *UserMessage) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use UserMessage.ProtoReflect.Descriptor instead.
func (*UserMessage) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{2}
}

func (x *UserMessage) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

// AbortRequest aborts the current generation.
type AbortRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Reason        string                 `protobuf:"bytes,1,opt,name=reason,proto3" json:"reason,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AbortRequest) Reset() {
	*x = AbortRequest{}
	mi := &file_llm_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AbortRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AbortRequest) ProtoMessage() {}

func (x *AbortRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AbortRequest.ProtoReflect.Descriptor instead.
func (*AbortRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{3}
}

func (x *AbortRequest) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

// ToolResult provides the result of a tool call.
type ToolResult struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ToolCallId    string                 `protobuf:"bytes,1,opt,name=tool_call_id,json=toolCallId,proto3" json:"tool_call_id,omitempty"`
	Result        string                 `protobuf:"bytes,2,opt,name=result,proto3" json:"result,omitempty"`
	IsError       bool                   `protobuf:"varint,3,opt,name=is_error,json=isError,proto3" json:"is_error,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolResult) Reset() {
	*x = ToolResult{}
	mi := &file_llm_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolResult) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolResult) ProtoMessage() {}

func (x *ToolResult) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolResult.ProtoReflect.Descriptor instead.
func (*ToolResult) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{4}
}

func (x *ToolResult) GetToolCallId() string {
	if x != nil {
		return x.ToolCallId
	}
	return ""
}

func (x *ToolResult) GetResult() string {
	if x != nil {
		return x.Result
	}
	return ""
}

func (x *ToolResult) GetIsError() bool {
	if x != nil {
		return x.IsError
	}
	return false
}

// Message represents a conversation message.
type Message struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Role          string                 `protobuf:"bytes,1,opt,name=role,proto3" json:"role,omitempty"` // "user", "assistant", "system"
	Content       string                 `protobuf:"bytes,2,opt,name=content,proto3" json:"content,omitempty"`
	ToolCalls     []*ToolCall            `protobuf:"bytes,3,rep,name=tool_calls,json=toolCalls,proto3" json:"tool_calls,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *Message) Reset() {
	*x = Message{}
	mi := &file_llm_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *Message) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*Message) ProtoMessage() {}

func (x *Message) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use Message.ProtoReflect.Descriptor instead.
func (*Message) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{5}
}

func (x *Message) GetRole() string {
	if x != nil {
		return x.Role
	}
	return ""
}

func (x *Message) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *Message) GetToolCalls() []*ToolCall {
	if x != nil {
		return x.ToolCalls
	}
	return nil
}

// ToolDefinition defines a tool for function calling.
type ToolDefinition struct {
	state          protoimpl.MessageState `protogen:"open.v1"`
	Name           string                 `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Description    string                 `protobuf:"bytes,2,opt,name=description,proto3" json:"description,omitempty"`
	ParametersJson string                 `protobuf:"bytes,3,opt,name=parameters_json,json=parametersJson,proto3" json:"parameters_json,omitempty"` // JSON schema for parameters
	unknownFields  protoimpl.UnknownFields
	sizeCache      protoimpl.SizeCache
}

func (x *ToolDefinition) Reset() {
	*x = ToolDefinition{}
	mi := &file_llm_proto_msgTypes[6]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolDefinition) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolDefinition) ProtoMessage() {}

func (x *ToolDefinition) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[6]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolDefinition.ProtoReflect.Descriptor instead.
func (*ToolDefinition) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{6}
}

func (x *ToolDefinition) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolDefinition) GetDescription() string {
	if x != nil {
		return x.Description
	}
	return ""
}

func (x *ToolDefinition) GetParametersJson() string {
	if x != nil {
		return x.ParametersJson
	}
	return ""
}

// ToolCall represents an LLM-generated tool call.
type ToolCall struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Id            string                 `protobuf:"bytes,1,opt,name=id,proto3" json:"id,omitempty"`
	Name          string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	ArgumentsJson string                 `protobuf:"bytes,3,opt,name=arguments_json,json=argumentsJson,proto3" json:"arguments_json,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolCall) Reset() {
	*x = ToolCall{}
	mi := &file_llm_proto_msgTypes[7]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolCall) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolCall) ProtoMessage() {}

func (x *ToolCall) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[7]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolCall.ProtoReflect.Descriptor instead.
func (*ToolCall) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{7}
}

func (x *ToolCall) GetId() string {
	if x != nil {
		return x.Id
	}
	return ""
}

func (x *ToolCall) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolCall) GetArgumentsJson() string {
	if x != nil {
		return x.ArgumentsJson
	}
	return ""
}

// ChatResponse is streamed from server to client.
type ChatResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Types that are valid to be assigned to Response:
	//
	//	*ChatResponse_SessionStarted
	//	*ChatResponse_Chunk
	//	*ChatResponse_ToolCall
	//	*ChatResponse_Completion
	//	*ChatResponse_Error
	//	*ChatResponse_Aborted
	Response      isChatResponse_Response `protobuf_oneof:"response"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ChatResponse) Reset() {
	*x = ChatResponse{}
	mi := &file_llm_proto_msgTypes[8]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ChatResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ChatResponse) ProtoMessage() {}

func (x *ChatResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[8]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ChatResponse.ProtoReflect.Descriptor instead.
func (*ChatResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{8}
}

func (x *ChatResponse) GetResponse() isChatResponse_Response {
	if x != nil {
		return x.Response
	}
	return nil
}

func (x *ChatResponse) GetSessionStarted() *SessionStarted {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_SessionStarted); ok {
			return x.SessionStarted
		}
	}
	return nil
}

func (x *ChatResponse) GetChunk() *ContentChunk {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_Chunk); ok {
			return x.Chunk
		}
	}
	return nil
}

func (x *ChatResponse) GetToolCall() *ToolCallRequest {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_ToolCall); ok {
			return x.ToolCall
		}
	}
	return nil
}

func (x *ChatResponse) GetCompletion() *CompletionResponse {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_Completion); ok {
			return x.Completion
		}
	}
	return nil
}

func (x *ChatResponse) GetError() *ErrorResponse {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_Error); ok {
			return x.Error
		}
	}
	return nil
}

func (x *ChatResponse) GetAborted() *AbortedResponse {
	if x != nil {
		if x, ok := x.Response.(*ChatResponse_Aborted); ok {
			return x.Aborted
		}
	}
	return nil
}

type isChatResponse_Response interface {
	isChatResponse_Response()
}

type ChatResponse_SessionStarted struct {
	// Session started successfully
	SessionStarted *SessionStarted `protobuf:"bytes,1,opt,name=session_started,json=sessionStarted,proto3,oneof"`
}

type ChatResponse_Chunk struct {
	// Content chunk (streamed tokens)
	Chunk *ContentChunk `protobuf:"bytes,2,opt,name=chunk,proto3,oneof"`
}

type ChatResponse_ToolCall struct {
	// Tool call requested by the LLM
	ToolCall *ToolCallRequest `protobuf:"bytes,3,opt,name=tool_call,json=toolCall,proto3,oneof"`
}

type ChatResponse_Completion struct {
	// Generation complete
	Completion *CompletionResponse `protobuf:"bytes,4,opt,name=completion,proto3,oneof"`
}

type ChatResponse_Error struct {
	// Error occurred
	Error *ErrorResponse `protobuf:"bytes,5,opt,name=error,proto3,oneof"`
}

type ChatResponse_Aborted struct {
	// Generation aborted (ack of AbortRequest)
	Aborted *AbortedResponse `protobuf:"bytes,6,opt,name=aborted,proto3,oneof"`
}

func (*ChatResponse_SessionStarted) isChatResponse_Response() {}

func (*ChatResponse_Chunk) isChatResponse_Response() {}

func (*ChatResponse_ToolCall) isChatResponse_Response() {}

func (*ChatResponse_Completion) isChatResponse_Response() {}

func (*ChatResponse_Error) isChatResponse_Response() {}

func (*ChatResponse_Aborted) isChatResponse_Response() {}

// SessionStarted confirms the session was initialized.
type SessionStarted struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	SessionId     string                 `protobuf:"bytes,1,opt,name=session_id,json=sessionId,proto3" json:"session_id,omitempty"`
	Provider      string                 `protobuf:"bytes,2,opt,name=provider,proto3" json:"provider,omitempty"`
	Model         string                 `protobuf:"bytes,3,opt,name=model,proto3" json:"model,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SessionStarted) Reset() {
	*x = SessionStarted{}
	mi := &file_llm_proto_msgTypes[9]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SessionStarted) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SessionStarted) ProtoMessage() {}

func (x *SessionStarted) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[9]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SessionStarted.ProtoReflect.Descriptor instead.
func (*SessionStarted) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{9}
}

func (x *SessionStarted) GetSessionId() string {
	if x != nil {
		return x.SessionId
	}
	return ""
}

func (x *SessionStarted) GetProvider() string {
	if x != nil {
		return x.Provider
	}
	return ""
}

func (x *SessionStarted) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

// ContentChunk streams generated content.
type ContentChunk struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	Index         int32                  `protobuf:"varint,2,opt,name=index,proto3" json:"index,omitempty"` // Chunk index for ordering
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ContentChunk) Reset() {
	*x = ContentChunk{}
	mi := &file_llm_proto_msgTypes[10]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ContentChunk) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ContentChunk) ProtoMessage() {}

func (x *ContentChunk) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[10]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ContentChunk.ProtoReflect.Descriptor instead.
func (*ContentChunk) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{10}
}

func (x *ContentChunk) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *ContentChunk) GetIndex() int32 {
	if x != nil {
		return x.Index
	}
	return 0
}

// ToolCallRequest indicates the LLM wants to call a tool.
type ToolCallRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ToolCallId    string                 `protobuf:"bytes,1,opt,name=tool_call_id,json=toolCallId,proto3" json:"tool_call_id,omitempty"`
	Name          string                 `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	ArgumentsJson string                 `protobuf:"bytes,3,opt,name=arguments_json,json=argumentsJson,proto3" json:"arguments_json,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ToolCallRequest) Reset() {
	*x = ToolCallRequest{}
	mi := &file_llm_proto_msgTypes[11]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ToolCallRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ToolCallRequest) ProtoMessage() {}

func (x *ToolCallRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[11]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ToolCallRequest.ProtoReflect.Descriptor instead.
func (*ToolCallRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{11}
}

func (x *ToolCallRequest) GetToolCallId() string {
	if x != nil {
		return x.ToolCallId
	}
	return ""
}

func (x *ToolCallRequest) GetName() string {
	if x != nil {
		return x.Name
	}
	return ""
}

func (x *ToolCallRequest) GetArgumentsJson() string {
	if x != nil {
		return x.ArgumentsJson
	}
	return ""
}

// CompletionResponse indicates generation is complete.
type CompletionResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	FullContent   string                 `protobuf:"bytes,1,opt,name=full_content,json=fullContent,proto3" json:"full_content,omitempty"`
	StopReason    string                 `protobuf:"bytes,2,opt,name=stop_reason,json=stopReason,proto3" json:"stop_reason,omitempty"`
	InputTokens   int64                  `protobuf:"varint,3,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`
	OutputTokens  int64                  `protobuf:"varint,4,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`
	CostUsd       float64                `protobuf:"fixed64,5,opt,name=cost_usd,json=costUsd,proto3" json:"cost_usd,omitempty"`
	LatencyMs     int64                  `protobuf:"varint,6,opt,name=latency_ms,json=latencyMs,proto3" json:"latency_ms,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *CompletionResponse) Reset() {
	*x = CompletionResponse{}
	mi := &file_llm_proto_msgTypes[12]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *CompletionResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*CompletionResponse) ProtoMessage() {}

func (x *CompletionResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[12]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use CompletionResponse.ProtoReflect.Descriptor instead.
func (*CompletionResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{12}
}

func (x *CompletionResponse) GetFullContent() string {
	if x != nil {
		return x.FullContent
	}
	return ""
}

func (x *CompletionResponse) GetStopReason() string {
	if x != nil {
		return x.StopReason
	}
	return ""
}

func (x *CompletionResponse) GetInputTokens() int64 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *CompletionResponse) GetOutputTokens() int64 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

func (x *CompletionResponse) GetCostUsd() float64 {
	if x != nil {
		return x.CostUsd
	}
	return 0
}

func (x *CompletionResponse) GetLatencyMs() int64 {
	if x != nil {
		return x.LatencyMs
	}
	return 0
}

// ErrorResponse indicates an error occurred.
type ErrorResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Code          string                 `protobuf:"bytes,1,opt,name=code,proto3" json:"code,omitempty"`
	Message       string                 `protobuf:"bytes,2,opt,name=message,proto3" json:"message,omitempty"`
	Retryable     bool                   `protobuf:"varint,3,opt,name=retryable,proto3" json:"retryable,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ErrorResponse) Reset() {
	*x = ErrorResponse{}
	mi := &file_llm_proto_msgTypes[13]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ErrorResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ErrorResponse) ProtoMessage() {}

func (x *ErrorResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[13]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ErrorResponse.ProtoReflect.Descriptor instead.
func (*ErrorResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{13}
}

func (x *ErrorResponse) GetCode() string {
	if x != nil {
		return x.Code
	}
	return ""
}

func (x *ErrorResponse) GetMessage() string {
	if x != nil {
		return x.Message
	}
	return ""
}

func (x *ErrorResponse) GetRetryable() bool {
	if x != nil {
		return x.Retryable
	}
	return false
}

// AbortedResponse confirms the generation was aborted.
type AbortedResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Reason        string                 `protobuf:"bytes,1,opt,name=reason,proto3" json:"reason,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *AbortedResponse) Reset() {
	*x = AbortedResponse{}
	mi := &file_llm_proto_msgTypes[14]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *AbortedResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*AbortedResponse) ProtoMessage() {}

func (x *AbortedResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[14]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use AbortedResponse.ProtoReflect.Descriptor instead.
func (*AbortedResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{14}
}

func (x *AbortedResponse) GetReason() string {
	if x != nil {
		return x.Reason
	}
	return ""
}

// SimpleChatRequest for unary RPC (non-streaming).
type SimpleChatRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	ApiKey        string                 `protobuf:"bytes,1,opt,name=api_key,json=apiKey,proto3" json:"api_key,omitempty"`
	Messages      []*Message             `protobuf:"bytes,2,rep,name=messages,proto3" json:"messages,omitempty"`
	SystemPrompt  string                 `protobuf:"bytes,3,opt,name=system_prompt,json=systemPrompt,proto3" json:"system_prompt,omitempty"`
	Model         string                 `protobuf:"bytes,4,opt,name=model,proto3" json:"model,omitempty"`
	MaxTokens     int32                  `protobuf:"varint,5,opt,name=max_tokens,json=maxTokens,proto3" json:"max_tokens,omitempty"`
	Temperature   float32                `protobuf:"fixed32,6,opt,name=temperature,proto3" json:"temperature,omitempty"`
	RequestId     string                 `protobuf:"bytes,7,opt,name=request_id,json=requestId,proto3" json:"request_id,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SimpleChatRequest) Reset() {
	*x = SimpleChatRequest{}
	mi := &file_llm_proto_msgTypes[15]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SimpleChatRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SimpleChatRequest) ProtoMessage() {}

func (x *SimpleChatRequest) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[15]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SimpleChatRequest.ProtoReflect.Descriptor instead.
func (*SimpleChatRequest) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{15}
}

func (x *SimpleChatRequest) GetApiKey() string {
	if x != nil {
		return x.ApiKey
	}
	return ""
}

func (x *SimpleChatRequest) GetMessages() []*Message {
	if x != nil {
		return x.Messages
	}
	return nil
}

func (x *SimpleChatRequest) GetSystemPrompt() string {
	if x != nil {
		return x.SystemPrompt
	}
	return ""
}

func (x *SimpleChatRequest) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *SimpleChatRequest) GetMaxTokens() int32 {
	if x != nil {
		return x.MaxTokens
	}
	return 0
}

func (x *SimpleChatRequest) GetTemperature() float32 {
	if x != nil {
		return x.Temperature
	}
	return 0
}

func (x *SimpleChatRequest) GetRequestId() string {
	if x != nil {
		return x.RequestId
	}
	return ""
}

// SimpleChatResponse for unary RPC.
type SimpleChatResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Content       string                 `protobuf:"bytes,1,opt,name=content,proto3" json:"content,omitempty"`
	Model         string                 `protobuf:"bytes,2,opt,name=model,proto3" json:"model,omitempty"`
	InputTokens   int64                  `protobuf:"varint,3,opt,name=input_tokens,json=inputTokens,proto3" json:"input_tokens,omitempty"`
	OutputTokens  int64                  `protobuf:"varint,4,opt,name=output_tokens,json=outputTokens,proto3" json:"output_tokens,omitempty"`
	CostUsd       float64                `protobuf:"fixed64,5,opt,name=cost_usd,json=costUsd,proto3" json:"cost_usd,omitempty"`
	LatencyMs     int64                  `protobuf:"varint,6,opt,name=latency_ms,json=latencyMs,proto3" json:"latency_ms,omitempty"`
	StopReason    string                 `protobuf:"bytes,7,opt,name=stop_reason,json=stopReason,proto3" json:"stop_reason,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *SimpleChatResponse) Reset() {
	*x = SimpleChatResponse{}
	mi := &file_llm_proto_msgTypes[16]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *SimpleChatResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*SimpleChatResponse) ProtoMessage() {}

func (x *SimpleChatResponse) ProtoReflect() protoreflect.Message {
	mi := &file_llm_proto_msgTypes[16]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use SimpleChatResponse.ProtoReflect.Descriptor instead.
func (*SimpleChatResponse) Descriptor() ([]byte, []int) {
	return file_llm_proto_rawDescGZIP(), []int{16}
}

func (x *SimpleChatResponse) GetContent() string {
	if x != nil {
		return x.Content
	}
	return ""
}

func (x *SimpleChatResponse) GetModel() string {
	if x != nil {
		return x.Model
	}
	return ""
}

func (x *SimpleChatResponse) GetInputTokens() int64 {
	if x != nil {
		return x.InputTokens
	}
	return 0
}

func (x *SimpleChatResponse) GetOutputTokens() int64 {
	if x != nil {
		return x.OutputTokens
	}
	return 0
}

func (x *SimpleChatResponse) GetCostUsd() float64 {
	if x != nil {
		return x.CostUsd
	}
	return 0
}

func (x *SimpleChatResponse) GetLatencyMs() int64 {
	if x != nil {
		return x.LatencyMs
	}
	return 0
}

func (x *SimpleChatResponse) GetStopReason() string {
	if x != nil {
		return x.StopReason
	}
	return ""
}

var File_llm_proto protoreflect.FileDescriptor

const file_llm_proto_rawDesc = "" +
	"\n" +
	"\tllm.proto\x12\x03llm\"\xd4\x01\n" +
	"\vChatRequest\x12-\n" +
	"\x05start\x18\x01 \x01(\v2\x15.llm.StartChatRequestH\x00R\x05start\x12,\n" +
	"\amessage\x18\x02 \x01(\v2\x10.llm.UserMessageH\x00R\amessage\x12)\n" +
	"\x05abort\x18\x03 \x01(\v2\x11.llm.AbortRequestH\x00R\x05abort\x122\n" +
	"\vtool_result\x18\x04 \x01(\v2\x0f.llm.ToolResultH\x00R\n" +
	"toolResultB\t\n" +
	"\arequest\"\x9b\x02\n" +
	"\x10StartChatRequest\x12\x17\n" +
	"\aapi_key\x18\x01 \x01(\tR\x06apiKey\x12#\n" +
	"\rsystem_prompt\x18\x02 \x01(\tR\fsystemPrompt\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x04 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vtemperature\x18\x05 \x01(\x02R\vtemperature\x12(\n" +
	"\bmessages\x18\x06 \x03(\v2\f.llm.MessageR\bmessages\x12)\n" +
	"\x05tools\x18\a \x03(\v2\x13.llm.ToolDefinitionR\x05tools\x12\x1d\n" +
	"\n" +
	"request_id\x18\b \x01(\tR\trequestId\"'\n" +
	"\vUserMessage\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\"&\n" +
	"\fAbortRequest\x12\x16\n" +
	"\x06reason\x18\x01 \x01(\tR\x06reason\"a\n" +
	"\n" +
	"ToolResult\x12 \n" +
	"\ftool_call_id\x18\x01 \x01(\tR\n" +
	"toolCallId\x12\x16\n" +
	"\x06result\x18\x02 \x01(\tR\x06result\x12\x19\n" +
	"\bis_error\x18\x03 \x01(\bR\aisError\"e\n" +
	"\aMessage\x12\x12\n" +
	"\x04role\x18\x01 \x01(\tR\x04role\x12\x18\n" +
	"\acontent\x18\x02 \x01(\tR\acontent\x12,\n" +
	"\n" +
	"tool_calls\x18\x03 \x03(\v2\r.llm.ToolCallR\ttoolCalls\"o\n" +
	"\x0eToolDefinition\x12\x12\n" +
	"\x04name\x18\x01 \x01(\tR\x04name\x12 \n" +
	"\vdescription\x18\x02 \x01(\tR\vdescription\x12'\n" +
	"\x0fparameters_json\x18\x03 \x01(\tR\x0eparametersJson\"U\n" +
	"\bToolCall\x12\x0e\n" +
	"\x02id\x18\x01 \x01(\tR\x02id\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12%\n" +
	"\x0earguments_json\x18\x03 \x01(\tR\rargumentsJson\"\xd3\x02\n" +
	"\fChatResponse\x12>\n" +
	"\x0fsession_started\x18\x01 \x01(\v2\x13.llm.SessionStartedH\x00R\x0esessionStarted\x12)\n" +
	"\x05chunk\x18\x02 \x01(\v2\x11.llm.ContentChunkH\x00R\x05chunk\x123\n" +
	"\ttool_call\x18\x03 \x01(\v2\x14.llm.ToolCallRequestH\x00R\btoolCall\x129\n" +
	"\n" +
	"completion\x18\x04 \x01(\v2\x17.llm.CompletionResponseH\x00R\n" +
	"completion\x12*\n" +
	"\x05error\x18\x05 \x01(\v2\x12.llm.ErrorResponseH\x00R\x05error\x120\n" +
	"\aaborted\x18\x06 \x01(\v2\x14.llm.AbortedResponseH\x00R\aabortedB\n" +
	"\n" +
	"\bresponse\"a\n" +
	"\x0eSessionStarted\x12\x1d\n" +
	"\n" +
	"session_id\x18\x01 \x01(\tR\tsessionId\x12\x1a\n" +
	"\bprovider\x18\x02 \x01(\tR\bprovider\x12\x14\n" +
	"\x05model\x18\x03 \x01(\tR\x05model\">\n" +
	"\fContentChunk\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x12\x14\n" +
	"\x05index\x18\x02 \x01(\x05R\x05index\"n\n" +
	"\x0fToolCallRequest\x12 \n" +
	"\ftool_call_id\x18\x01 \x01(\tR\n" +
	"toolCallId\x12\x12\n" +
	"\x04name\x18\x02 \x01(\tR\x04name\x12%\n" +
	"\x0earguments_json\x18\x03 \x01(\tR\rargumentsJson\"\xda\x01\n" +
	"\x12CompletionResponse\x12!\n" +
	"\ffull_content\x18\x01 \x01(\tR\vfullContent\x12\x1f\n" +
	"\vstop_reason\x18\x02 \x01(\tR\n" +
	"stopReason\x12!\n" +
	"\finput_tokens\x18\x03 \x01(\x03R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\x04 \x01(\x03R\foutputTokens\x12\x19\n" +
	"\bcost_usd\x18\x05 \x01(\x01R\acostUsd\x12\x1d\n" +
	"\n" +
	"latency_ms\x18\x06 \x01(\x03R\tlatencyMs\"[\n" +
	"\rErrorResponse\x12\x12\n" +
	"\x04code\x18\x01 \x01(\tR\x04code\x12\x18\n" +
	"\amessage\x18\x02 \x01(\tR\amessage\x12\x1c\n" +
	"\tretryable\x18\x03 \x01(\bR\tretryable\")\n" +
	"\x0fAbortedResponse\x12\x16\n" +
	"\x06reason\x18\x01 \x01(\tR\x06reason\"\xf1\x01\n" +
	"\x11SimpleChatRequest\x12\x17\n" +
	"\aapi_key\x18\x01 \x01(\tR\x06apiKey\x12(\n" +
	"\bmessages\x18\x02 \x03(\v2\f.llm.MessageR\bmessages\x12#\n" +
	"\rsystem_prompt\x18\x03 \x01(\tR\fsystemPrompt\x12\x14\n" +
	"\x05model\x18\x04 \x01(\tR\x05model\x12\x1d\n" +
	"\n" +
	"max_tokens\x18\x05 \x01(\x05R\tmaxTokens\x12 \n" +
	"\vtemperature\x18\x06 \x01(\x02R\vtemperature\x12\x1d\n" +
	"\n" +
	"request_id\x18\a \x01(\tR\trequestId\"\xe7\x01\n" +
	"\x12SimpleChatResponse\x12\x18\n" +
	"\acontent\x18\x01 \x01(\tR\acontent\x12\x14\n" +
	"\x05model\x18\x02 \x01(\tR\x05model\x12!\n" +
	"\finput_tokens\x18\x03 \x01(\x03R\vinputTokens\x12#\n" +
	"\routput_tokens\x18\x04 \x01(\x03R\foutputTokens\x12\x19\n" +
	"\bcost_usd\x18\x05 \x01(\x01R\acostUsd\x12\x1d\n" +
	"\n" +
	"latency_ms\x18\x06 \x01(\x03R\tlatencyMs\x12\x1f\n" +
	"\vstop_reason\x18\a \x01(\tR\n" +
	"stopReason2|\n" +
	"\n" +
	"LLMService\x12/\n" +
	"\x04Chat\x12\x10.llm.ChatRequest\x1a\x11.llm.ChatResponse(\x010\x01\x12=\n" +
	"\n" +
	"SimpleChat\x12\x16.llm.SimpleChatRequest\x1a\x17.llm.SimpleChatResponseB%Z#github.com/almatuck/levee-sdk/llmpbb\x06proto3"

var (
	file_llm_proto_rawDescOnce sync.Once
	file_llm_proto_rawDescData []byte
)

func file_llm_proto_rawDescGZIP() []byte {
	file_llm_proto_rawDescOnce.Do(func() {
		file_llm_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_llm_proto_rawDesc), len(file_llm_proto_rawDesc)))
	})
	return file_llm_proto_rawDescData
}

var file_llm_proto_msgTypes = make([]protoimpl.MessageInfo, 17)
var file_llm_proto_goTypes = []any{
	(*ChatRequest)(nil),        // 0: llm.ChatRequest
	(*StartChatRequest)(nil),   // 1: llm.StartChatRequest
	(*UserMessage)(nil),        // 2: llm.UserMessage
	(*AbortRequest)(nil),       // 3: llm.AbortRequest
	(*ToolResult)(nil),         // 4: llm.ToolResult
	(*Message)(nil),            // 5: llm.Message
	(*ToolDefinition)(nil),     // 6: llm.ToolDefinition
	(*ToolCall)(nil),           // 7: llm.ToolCall
	(*ChatResponse)(nil),       // 8: llm.ChatResponse
	(*SessionStarted)(nil),     // 9: llm.SessionStarted
	(*ContentChunk)(nil),       // 10: llm.ContentChunk
	(*ToolCallRequest)(nil),    // 11: llm.ToolCallRequest
	(*CompletionResponse)(nil), // 12: llm.CompletionResponse
	(*ErrorResponse)(nil),      // 13: llm.ErrorResponse
	(*AbortedResponse)(nil),    // 14: llm.AbortedResponse
	(*SimpleChatRequest)(nil),  // 15: llm.SimpleChatRequest
	(*SimpleChatResponse)(nil), // 16: llm.SimpleChatResponse
}
var file_llm_proto_depIdxs = []int32{
	1,  // 0: llm.ChatRequest.start:type_name -> llm.StartChatRequest
	2,  // 1: llm.ChatRequest.message:type_name -> llm.UserMessage
	3,  // 2: llm.ChatRequest.abort:type_name -> llm.AbortRequest
	4,  // 3: llm.ChatRequest.tool_result:type_name -> llm.ToolResult
	5,  // 4: llm.StartChatRequest.messages:type_name -> llm.Message
	6,  // 5: llm.StartChatRequest.tools:type_name -> llm.ToolDefinition
	7,  // 6: llm.Message.tool_calls:type_name -> llm.ToolCall
	9,  // 7: llm.ChatResponse.session_started:type_name -> llm.SessionStarted
	10, // 8: llm.ChatResponse.chunk:type_name -> llm.ContentChunk
	11, // 9: llm.ChatResponse.tool_call:type_name -> llm.ToolCallRequest
	12, // 10: llm.ChatResponse.completion:type_name -> llm.CompletionResponse
	13, // 11: llm.ChatResponse.error:type_name -> llm.ErrorResponse
	14, // 12: llm.ChatResponse.aborted:type_name -> llm.AbortedResponse
	5,  // 13: llm.SimpleChatRequest.messages:type_name -> llm.Message
	0,  // 14: llm.LLMService.Chat:input_type -> llm.ChatRequest
	15, // 15: llm.LLMService.SimpleChat:input_type -> llm.SimpleChatRequest
	8,  // 16: llm.LLMService.Chat:output_type -> llm.ChatResponse
	16, // 17: llm.LLMService.SimpleChat:output_type -> llm.SimpleChatResponse
	16, // [16:18] is the sub-list for method output_type
	14, // [14:16] is the sub-list for method input_type
	14, // [14:14] is the sub-list for extension type_name
	14, // [14:14] is the sub-list for extension extendee
	0,  // [0:14] is the sub-list for field type_name
}

func init() { file_llm_proto_init() }
func file_llm_proto_init() {
	if File_llm_proto != nil {
		return
	}
	file_llm_proto_msgTypes[0].OneofWrappers = []any{
		(*ChatRequest_Start)(nil),
		(*ChatRequest_Message)(nil),
		(*ChatRequest_Abort)(nil),
		(*ChatRequest_ToolResult)(nil),
	}
	file_llm_proto_msgTypes[8].OneofWrappers = []any{
		(*ChatResponse_SessionStarted)(nil),
		(*ChatResponse_Chunk)(nil),
		(*ChatResponse_ToolCall)(nil),
		(*ChatResponse_Completion)(nil),
		(*ChatResponse_Error)(nil),
		(*ChatResponse_Aborted)(nil),
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_llm_proto_rawDesc), len(file_llm_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   17,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_llm_proto_goTypes,
		DependencyIndexes: file_llm_proto_depIdxs,
		MessageInfos:      file_llm_proto_msgTypes,
	}.Build()
	File_llm_proto = out.File
	file_llm_proto_goTypes = nil
	file_llm_proto_depIdxs = nil
}
